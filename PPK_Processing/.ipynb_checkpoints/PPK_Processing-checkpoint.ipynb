{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPK processing of \"Stop and Go\" data\n",
    "\n",
    "**Script prepared by A. Rovere - MARUM, University of Bremen**\n",
    "\n",
    "This script can be used to process GNSS data acquired in \"stop-and-go\" mode. The script needs the following inputs:\n",
    "\n",
    " - Rover data processed with RTKlib as kinematic points and saved as *.pos* file\n",
    " - Files exported from the data collector in *.csv* format\n",
    "\n",
    "The script first merges the data collector files into a single dataframe. Then, postprocessed rover data is imported and a new dataframe is created with time-averaged postprocessed static positions acquired in FIX status. Time-averaged positions are also calculated for FLOAT and SINGLE status datapoints. All the results are saved in a multi-sheet excel file.\n",
    "\n",
    "For a guide on how to use the NRCAN system and RTKlib with EMLID GPS, see:\n",
    "\n",
    "https://docs.emlid.com/reach/common/tutorials/ppp-introduction/\n",
    "\n",
    "This discussion on the EMLID forum contains some useful insights on the processing, as well another (similar) tool, including an intuitive user interface. The results of this script compare well with those obtained from this tool.\n",
    "\n",
    "https://community.emlid.com/t/ppk-point-extractor-software/12822/46\n",
    "\n",
    "## RTKlib setup\n",
    "In RTKlib, remember to set up **output time in UTC**\n",
    "\n",
    "For a guide on how to process your data with RTKlib, see:\n",
    "\n",
    "https://docs.emlid.com/reach/common/tutorials/gps-post-processing/\n",
    "\n",
    "A typical RTKlib configuration is annexed in the script main folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages needed\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "import sys\n",
    "import xlsxwriter as writer\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input folders and data\n",
    "Indicate the folders where data is contained and the output file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Output file name\n",
    "out='Example_output.xlsx'\n",
    "#Folder where the csv file from the data collector is stored\n",
    "csv_folder = r'\\Example_data\\Rover\\Data_collector'\n",
    "#Folder where pos files from RTKlib processing are stored\n",
    "processed_data = r'\\Example_data\\Rover\\Processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate the 2-sigma uncertainties for Latitude, Longitude and Ellipsoid Height of the base station. These values will be taken into account when calculating final point uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#95% sigma Latitude\n",
    "LATsigma = 0.102\n",
    "#95% sigma Longitude\n",
    "LONsigma = 0.193\n",
    "#95% sigma Ellipsoid height\n",
    "Hsigma = 0.198\n",
    "#Number of rows to skip in the pos file\n",
    "num=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data collector files\n",
    "Include in one folder all the *.csv* files exported from the data collector (Apple or Android) with ReachView software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.realpath('')+csv_folder\n",
    "all_files = glob.glob(dirname + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    df['filename'] = os.path.basename(filename)\n",
    "    li.append(df)\n",
    "rawpoints = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658c06abd5e44f68b1e1c0bf6ef1c0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Name of point', layout=Layout(width='max-content'), options=('index', 'name', 'longitude…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52d1569499441a49dcd3162044ab197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Start of data collection (yyyy-mm-dd UTC)', layout=Layout(width='max-content'), options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c54f6993f7949c1a511c5134fd2f596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='End of data collection (yyyy-mm-dd UTC)', layout=Layout(width='max-content'), options=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49eb74c6c2b04b78a68d5c0d047ace26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Total points sampled in the field', layout=Layout(width='max-content'), options=('index'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0eec73d55b4b75b9166a677f4faf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Rover Antenna height (m)', layout=Layout(width='max-content'), options=('index', 'name',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "name=widgets.Dropdown(\n",
    "    options=rawpoints.columns,\n",
    "    description='Name of point',\n",
    "    disabled=False,layout={'width': 'max-content'},style=style)\n",
    "start=widgets.Dropdown(\n",
    "    options=rawpoints.columns,\n",
    "    description='Start of data collection (yyyy-mm-dd UTC)',\n",
    "    disabled=False,layout={'width': 'max-content'},style=style)\n",
    "end=widgets.Dropdown(\n",
    "    options=rawpoints.columns,\n",
    "    description='End of data collection (yyyy-mm-dd UTC)',\n",
    "    disabled=False,layout={'width': 'max-content'},style=style)\n",
    "count=widgets.Dropdown(\n",
    "    options=rawpoints.columns,\n",
    "    description='Total points sampled in the field',\n",
    "    disabled=False,layout={'width': 'max-content'},style=style)\n",
    "ant_h=widgets.Dropdown(\n",
    "    options=rawpoints.columns,\n",
    "    description='Rover Antenna height (m)',\n",
    "    disabled=False,\n",
    "    layout={'width': 'max-content'},style=style)\n",
    "\n",
    "display(name, start, end, count,ant_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "rawpoints[start.value] = rawpoints[start.value].astype('datetime64[ns]')\n",
    "rawpoints[end.value] = rawpoints[end.value].astype('datetime64[ns]')\n",
    "rawpoints.sort_values(by=[start.value],inplace=True)\n",
    "rawpoints.reset_index(inplace=True)\n",
    "rawpoints.rename(columns={name.value:'POINT ID',\n",
    "                          start.value:'Start of data collection (yyyy-mm-dd UTC)',\n",
    "                         end.value:'End of data collection (yyyy-mm-dd UTC)',\n",
    "                         count.value:'Total points sampled in the field',\n",
    "                         ant_h.value:'Rover Antenna height (m)'},inplace=True)\n",
    "rawpoints.drop(columns=['level_0','index'],inplace=True)\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(out, engine='xlsxwriter',\n",
    "                        options={'strings_to_numbers': True,\n",
    "                                 'strings_to_formulas': False})\n",
    "workbook=writer.book\n",
    "wrap = workbook.add_format({'text_wrap': True, \n",
    "                            'valign':'vcenter',\n",
    "                            'align':'center'})\n",
    "\n",
    "rawpoints.to_excel(writer, sheet_name='Raw collector data', index=False)\n",
    "worksheet = writer.sheets['Raw collector data']\n",
    "worksheet.set_column('A:ZZ',20,wrap)\n",
    "header_format = workbook.add_format({'bold': True,'text_wrap': True,'valign': 'vcenter','align':'center',\n",
    "                                     'fg_color':'#C0C0C0','border': 1})\n",
    "for col_num, value in enumerate(rawpoints.columns.values):\n",
    "    worksheet.write(0, col_num, value, header_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessed GPS points\n",
    "Include in one folder all the *.pos* data processed with RTKlib. The data need to be processed as \"kinematic\" points. For each point included in the data collector files, the script selects the corresponding processed points following the start and end timestamps. The script then calculates average and ±1sigma positions based on the postprocessed rover kinematic data. A further calculation of uncertainties incorporates the base station sigma values in the final uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "dirname = os.path.realpath('')+processed_data\n",
    "all_files = glob.glob(dirname + \"/*.pos\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,skiprows=num,delim_whitespace=True,parse_dates=[['%', 'UTC']])\n",
    "    li.append(df)\n",
    "processed = pd.concat(li, axis=0, ignore_index=True)\n",
    "processed.reset_index(inplace=True)\n",
    "processed['%_UTC'] = pd.to_datetime(processed['%_UTC'])\n",
    "\n",
    "# Process points with a FIX solution available\n",
    "processedQ1=processed.loc[processed['Q'] == 1]\n",
    "dataQ1 = []\n",
    "for index, row in rawpoints.iterrows():\n",
    "    time_start=rawpoints['Start of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    time_end=rawpoints['End of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    processed_clip=processedQ1[(processedQ1['%_UTC'] >= time_start) & (processedQ1['%_UTC'] <=time_end)]\n",
    "    row['Average postprocessed antenna Ellipsoid height (m)']=processed_clip['height(m)'].mean()\n",
    "    row['Postprocessed Ellipsoid height ±2sigma (m)']=processed_clip['height(m)'].std()*2\n",
    "    row['Average postprocessed latitude (degrees)']=processed_clip['latitude(deg)'].mean()\n",
    "    row['Postprocessed latitude ±2sigma (degrees)']=processed_clip['latitude(deg)'].std()*2\n",
    "    row['Average postprocessed longitude (degrees)']=processed_clip['longitude(deg)'].mean()\n",
    "    row['Postprocessed Longitude ±2sigma (degrees)']=processed_clip['longitude(deg)'].std()*2\n",
    "    row['Number of fix points processed']=processed_clip.loc[processed_clip.Q == 1, 'Q'].count()\n",
    "    dataQ1.append(row)\n",
    "dataQ1 = pd.DataFrame(dataQ1)\n",
    "dataQ1 = dataQ1.dropna()\n",
    "dataQ1['Ellipsoid heigh corrected for Rover antenna height (m)']=dataQ1['Average postprocessed antenna Ellipsoid height (m)']-dataQ1['Rover Antenna height (m)']\n",
    "dataQ1['Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ1['Postprocessed Ellipsoid height ±2sigma (m)'])+np.square(float(Hsigma)))\n",
    "dataQ1['Postprocessed Latitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ1['Postprocessed latitude ±2sigma (degrees)'])+np.square(float(LATsigma)))\n",
    "dataQ1['Postprocessed Longitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ1['Postprocessed Longitude ±2sigma (degrees)'])+np.square(float(LONsigma)))\n",
    "\n",
    "dataQ1 = dataQ1[['filename','POINT ID','Start of data collection (yyyy-mm-dd UTC)','End of data collection (yyyy-mm-dd UTC)',\n",
    "                 'Total points sampled in the field','Number of fix points processed','Rover Antenna height (m)',\n",
    "                 'Average postprocessed antenna Ellipsoid height (m)',\n",
    "                 'Ellipsoid heigh corrected for Rover antenna height (m)','Postprocessed Ellipsoid height ±2sigma (m)',\n",
    "                 'Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed latitude (degrees)','Postprocessed latitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Latitude including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed longitude (degrees)','Postprocessed Longitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Longitude including base uncertainty ±2sigma (m)']]\n",
    "#Write Q1 excel\n",
    "if not dataQ1.empty:\n",
    "    dataQ1.to_excel(writer, sheet_name='Postprocessed GPS points FIX', index=False)\n",
    "    worksheet = writer.sheets['Postprocessed GPS points FIX']\n",
    "    worksheet.set_column('A:ZZ',20,wrap)\n",
    "    header_format = workbook.add_format({'bold': True,'text_wrap': True,'valign': 'vcenter','align':'center',\n",
    "                                     'fg_color':'#C0C0C0','border': 1})\n",
    "    for col_num, value in enumerate(dataQ1.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "# Process points with a FLOAT solution available\n",
    "processedQ2=processed.loc[processed['Q'] == 2]\n",
    "dataQ2 = []\n",
    "for index, row in rawpoints.iterrows():\n",
    "    time_start=rawpoints['Start of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    time_end=rawpoints['End of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    processed_clip=processedQ2[(processedQ2['%_UTC'] >= time_start) & (processedQ2['%_UTC'] <=time_end)]\n",
    "    row['Average postprocessed antenna Ellipsoid height (m)']=processed_clip['height(m)'].mean()\n",
    "    row['Postprocessed Ellipsoid height ±2sigma (m)']=processed_clip['height(m)'].std()*2\n",
    "    row['Average postprocessed latitude (degrees)']=processed_clip['latitude(deg)'].mean()\n",
    "    row['Postprocessed latitude ±2sigma (degrees)']=processed_clip['latitude(deg)'].std()*2\n",
    "    row['Average postprocessed longitude (degrees)']=processed_clip['longitude(deg)'].mean()\n",
    "    row['Postprocessed Longitude ±2sigma (degrees)']=processed_clip['longitude(deg)'].std()*2\n",
    "    row['Number of float points processed']=processed_clip.loc[processed_clip.Q == 2, 'Q'].count()\n",
    "    dataQ2.append(row)\n",
    "dataQ2 = pd.DataFrame(dataQ2)\n",
    "dataQ2 = dataQ2.dropna()\n",
    "dataQ2['Ellipsoid heigh corrected for Rover antenna height (m)']=dataQ2['Average postprocessed antenna Ellipsoid height (m)']-dataQ2['Rover Antenna height (m)']\n",
    "dataQ2['Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ2['Postprocessed Ellipsoid height ±2sigma (m)'])+np.square(float(Hsigma)))\n",
    "dataQ2['Postprocessed Latitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ2['Postprocessed latitude ±2sigma (degrees)'])+np.square(float(LATsigma)))\n",
    "dataQ2['Postprocessed Longitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ2['Postprocessed Longitude ±2sigma (degrees)'])+np.square(float(LONsigma)))\n",
    "\n",
    "dataQ2 = dataQ2[['filename','POINT ID','Start of data collection (yyyy-mm-dd UTC)','End of data collection (yyyy-mm-dd UTC)',\n",
    "                 'Total points sampled in the field','Number of float points processed','Rover Antenna height (m)',\n",
    "                 'Average postprocessed antenna Ellipsoid height (m)',\n",
    "                 'Ellipsoid heigh corrected for Rover antenna height (m)','Postprocessed Ellipsoid height ±2sigma (m)',\n",
    "                 'Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed latitude (degrees)','Postprocessed latitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Latitude including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed longitude (degrees)','Postprocessed Longitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Longitude including base uncertainty ±2sigma (m)']]\n",
    "#Write Q2 excel\n",
    "if not dataQ2.empty:\n",
    "    dataQ2.to_excel(writer, sheet_name='Postprocessed GPS points FLOAT', index=False)\n",
    "    worksheet = writer.sheets['Postprocessed GPS points FLOAT']\n",
    "    worksheet.set_column('A:ZZ',20,wrap)\n",
    "    header_format = workbook.add_format({'bold': True,'text_wrap': True,\n",
    "                                         'valign': 'vcenter','align':'center',\n",
    "                                         'fg_color':'#C0C0C0','border': 1})\n",
    "    for col_num, value in enumerate(dataQ2.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "# Process points with a SBAS solution available\n",
    "processedQ3=processed.loc[processed['Q'] == 3]\n",
    "dataQ3 = []\n",
    "for index, row in rawpoints.iterrows():\n",
    "    time_start=rawpoints['Start of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    time_end=rawpoints['End of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    processed_clip=processedQ3[(processedQ3['%_UTC'] >= time_start) & (processedQ3['%_UTC'] <=time_end)]\n",
    "    row['Average postprocessed antenna Ellipsoid height (m)']=processed_clip['height(m)'].mean()\n",
    "    row['Postprocessed Ellipsoid height ±2sigma (m)']=processed_clip['height(m)'].std()*2\n",
    "    row['Average postprocessed latitude (degrees)']=processed_clip['latitude(deg)'].mean()\n",
    "    row['Postprocessed latitude ±2sigma (degrees)']=processed_clip['latitude(deg)'].std()*2\n",
    "    row['Average postprocessed longitude (degrees)']=processed_clip['longitude(deg)'].mean()\n",
    "    row['Postprocessed Longitude ±2sigma (degrees)']=processed_clip['longitude(deg)'].std()*2\n",
    "    row['Number of sbas points processed']=processed_clip.loc[processed_clip.Q == 3, 'Q'].count()\n",
    "    dataQ3.append(row)\n",
    "dataQ3 = pd.DataFrame(dataQ3)\n",
    "dataQ3 = dataQ3.dropna()\n",
    "dataQ3['Ellipsoid heigh corrected for Rover antenna height (m)']=dataQ3['Average postprocessed antenna Ellipsoid height (m)']-dataQ3['Rover Antenna height (m)']\n",
    "dataQ3['Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ3['Postprocessed Ellipsoid height ±2sigma (m)'])+np.square(float(Hsigma)))\n",
    "dataQ3['Postprocessed Latitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ3['Postprocessed latitude ±2sigma (degrees)'])+np.square(float(LATsigma)))\n",
    "dataQ3['Postprocessed Longitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ3['Postprocessed Longitude ±2sigma (degrees)'])+np.square(float(LONsigma)))\n",
    "\n",
    "dataQ3 = dataQ3[['filename','POINT ID','Start of data collection (yyyy-mm-dd UTC)','End of data collection (yyyy-mm-dd UTC)',\n",
    "                 'Total points sampled in the field','Number of sbas points processed','Rover Antenna height (m)',\n",
    "                 'Average postprocessed antenna Ellipsoid height (m)',\n",
    "                 'Ellipsoid heigh corrected for Rover antenna height (m)','Postprocessed Ellipsoid height ±2sigma (m)',\n",
    "                 'Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed latitude (degrees)','Postprocessed latitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Latitude including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed longitude (degrees)','Postprocessed Longitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Longitude including base uncertainty ±2sigma (m)']]\n",
    "#Write Q3 excel\n",
    "if not dataQ3.empty:\n",
    "    dataQ3.to_excel(writer, sheet_name='Postprocessed GPS points SBAS', index=False)\n",
    "    worksheet = writer.sheets['Postprocessed GPS points SBAS']\n",
    "    worksheet.set_column('A:ZZ',20,wrap)\n",
    "    header_format = workbook.add_format({'bold': True,'text_wrap': True,\n",
    "                                         'valign': 'vcenter','align':'center',\n",
    "                                         'fg_color':'#C0C0C0','border': 1})\n",
    "    for col_num, value in enumerate(dataQ3.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)\n",
    "\n",
    "# Process points with a SINGLE solution available\n",
    "processedQ5=processed.loc[processed['Q'] == 5]\n",
    "dataQ5 = []\n",
    "for index, row in rawpoints.iterrows():\n",
    "    time_start=rawpoints['Start of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    time_end=rawpoints['End of data collection (yyyy-mm-dd UTC)'].values[index]\n",
    "    processed_clip=processedQ5[(processedQ5['%_UTC'] >= time_start) & (processedQ5['%_UTC'] <=time_end)]\n",
    "    row['Average postprocessed antenna Ellipsoid height (m)']=processed_clip['height(m)'].mean()\n",
    "    row['Postprocessed Ellipsoid height ±2sigma (m)']=processed_clip['height(m)'].std()*2\n",
    "    row['Average postprocessed latitude (degrees)']=processed_clip['latitude(deg)'].mean()\n",
    "    row['Postprocessed latitude ±2sigma (degrees)']=processed_clip['latitude(deg)'].std()*2\n",
    "    row['Average postprocessed longitude (degrees)']=processed_clip['longitude(deg)'].mean()\n",
    "    row['Postprocessed Longitude ±2sigma (degrees)']=processed_clip['longitude(deg)'].std()*2\n",
    "    row['Number of single points processed']=processed_clip.loc[processed_clip.Q == 5, 'Q'].count()\n",
    "    dataQ5.append(row)\n",
    "dataQ5 = pd.DataFrame(dataQ5)\n",
    "dataQ5 = dataQ5.dropna()\n",
    "dataQ5['Ellipsoid heigh corrected for Rover antenna height (m)']=dataQ5['Average postprocessed antenna Ellipsoid height (m)']-dataQ5['Rover Antenna height (m)']\n",
    "dataQ5['Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ5['Postprocessed Ellipsoid height ±2sigma (m)'])+np.square(float(Hsigma)/2))\n",
    "dataQ5['Postprocessed Latitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ5['Postprocessed latitude ±2sigma (degrees)'])+np.square(float(LATsigma)/2))\n",
    "dataQ5['Postprocessed Longitude including base uncertainty ±2sigma (m)']=np.sqrt(np.square(dataQ5['Postprocessed Longitude ±2sigma (degrees)'])+np.square(float(LONsigma)/2))\n",
    "\n",
    "dataQ5 = dataQ5[['filename','POINT ID','Start of data collection (yyyy-mm-dd UTC)','End of data collection (yyyy-mm-dd UTC)',\n",
    "                 'Total points sampled in the field','Number of single points processed','Rover Antenna height (m)',\n",
    "                 'Average postprocessed antenna Ellipsoid height (m)',\n",
    "                 'Ellipsoid heigh corrected for Rover antenna height (m)','Postprocessed Ellipsoid height ±2sigma (m)',\n",
    "                 'Postprocessed Ellipsoid height including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed latitude (degrees)','Postprocessed latitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Latitude including base uncertainty ±2sigma (m)',\n",
    "                 'Average postprocessed longitude (degrees)','Postprocessed Longitude ±2sigma (degrees)',\n",
    "                 'Postprocessed Longitude including base uncertainty ±2sigma (m)']]\n",
    "#Write Q5 excel\n",
    "if not dataQ5.empty:\n",
    "    dataQ5.to_excel(writer, sheet_name='Postprocessed GPS points SINGLE', index=False)\n",
    "    worksheet = writer.sheets['Postprocessed GPS points SINGLE']\n",
    "    worksheet.set_column('A:ZZ',20,wrap)\n",
    "    header_format = workbook.add_format({'bold': True,'text_wrap': True,\n",
    "                                         'valign': 'vcenter','align':'center',\n",
    "                                         'fg_color':'#C0C0C0','border': 1})\n",
    "    for col_num, value in enumerate(dataQ5.columns.values):\n",
    "        worksheet.write(0, col_num, value, header_format)        \n",
    "        \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of outputs\n",
    "The output of this script is an excel file (*.xslx*) containing different sheets.\n",
    " - **Raw collector data.** These are the data downloaded from the collector, with minimal adustments on column names\n",
    " - **Postprocessed GPS points FIX/FLOAT/SBAS/SINGLE.** Postprocessed FIX, FLOAT SBAS or SINGLE points organized in different sheets.\n",
    " \n",
    "#### Legend for Postprocessed GPS points\n",
    "\n",
    "***filename:*** The original data collector *csv* file.\n",
    "\n",
    "***POINT ID:*** Original point ID as assigned during data collection. \n",
    "\n",
    "***Start of data collection (yyyy-mm-dd UTC):*** Start of raw data collection.\n",
    "\n",
    "***End of data collection (yyyy-mm-dd UTC):*** End of raw data collection.\n",
    "\n",
    "***Total points sampled in the field:*** Total points sampled during the survey in static mode.\n",
    "\n",
    "***Number of fix points processed:*** Total points processed, concurring to the average calculations.\n",
    "\n",
    "***Rover Antenna height (m):*** Rover antenna height as assigned originally in the field.\n",
    "\n",
    "***Average postprocessed antenna Ellipsoid height (m):*** Average of postprocessed ellipsoid heights.\n",
    "\n",
    "***Ellipsoid heigh corrected for Rover antenna height (m):*** Average of postprocessed ellipsoid heights corrected for antenna height. **Use this value as final elevation.** \n",
    "\n",
    "***Postprocessed Ellipsoid height 2sigma (m):*** Standard deviation of postprocessed ellipsoid heights.\n",
    "\n",
    "***Postprocessed Ellipsoid height including base uncertainty 2sigma (m):*** Standard deviation of postprocessed ellipsoid heights, including uncertainty propagated in root mean square from the base processing. **Use this value as final elevation uncertainty.**\n",
    "\n",
    "***Average postprocessed latitude (degrees):*** Average of postprocessed latitude corrected for antenna height. **Use this value as final latitude.** \n",
    "\n",
    "***Postprocessed latitude 2sigma (degrees):*** Standard deviation of postprocessed latitude values.\n",
    "\n",
    "***Postprocessed Latitude including base uncertainty 2sigma (m):*** Standard deviation of postprocessed latitude values, including uncertainty propagated in root mean square from the base processing. **Use this value as final latitude uncertainty.**\n",
    "\n",
    "***Average postprocessed longitude (degrees):*** Average of postprocessed longitude corrected for antenna height. **Use this value as final longitude.** \n",
    "\n",
    "***Postprocessed longitude 2sigma (degrees):*** Standard deviation of postprocessed longitude values.\n",
    "\n",
    "***Postprocessed longitude including base uncertainty 2sigma (m):*** Standard deviation of postprocessed longitude values, including uncertainty propagated in root mean square from the base processing. **Use this value as final longitude uncertainty.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## License\n",
    "This software is relased under the MIT license.\n",
    "\n",
    "Copyright 2020 Alessio Rovere\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "***\n",
    "# Research funding acknowledgments\n",
    "This script and associated data were created in the framework of the European Reasearch Council Starting Grant WARMCOASTS (Grant Agreement Number 802414), funded under the European Union's Horizon 2020 research and Innovation programme.\n",
    "***\n",
    "# Code acknowledgments\n",
    "https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f\n",
    "https://kite.com/python/answers/how-to-redirect-print-output-to-a-text-file-in-python\n",
    "https://stackoverflow.com/questions/41857659/python-pandas-add-filename-column-csv\n",
    "https://stackoverflow.com/questions/46184239/extract-a-page-from-a-pdf-as-a-jpeg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
